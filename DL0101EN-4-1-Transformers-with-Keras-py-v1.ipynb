{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0101EN-SkillsNetwork/images/IDSN-logo.png\" width=\"400\"> </a>\n",
    "\n",
    "# Transformers with Keras\n",
    "\n",
    "Estimated time needed **45** mins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will learn how to use the Keras library to build a transformer using a sequence-to-sequence architecture with self-attention for translation. We will train the model using a sample dataset and then use this model for English to Spanish translation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives for this Notebook    \n",
    "* How to use the Keras library to build transformers model\n",
    "* Train the transformer model using a given dataset\n",
    "* Use the trained transformer model to translate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 4>\n",
    "1. <a href=\"#Import-Keras-and-Packages\">Import Keras and Packages</a><br>\n",
    "2. <a href=\"#Step-1:-Data-Preparation\">Step 1: Data Preparation</a><br>\n",
    "3. <a href=\"#Step-2:-Self-Attention-Layer\">Step 2: Self-Attention Layer</a><br>\n",
    "4. <a href=\"#Step-3:-Model-Architecture\">Step 3: Model Architecture</a><br>\n",
    "5. <a href=\"#Step-4:-Training-the-Model\">Step 4: Training the Model</a><br>\n",
    "6. <a href=\"#Step-5:-Plotting-the-training-loss\">Step 5: Plotting the training loss</a><br>\n",
    "\n",
    "</font>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Keras and Packages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the keras libraries and the packages that we would need to build a neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following required libraries are __not__ pre-installed in the Skills Network Labs environment. __You will need to run the following cell__ to install them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.17.1\n",
      "  Downloading tensorflow-2.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (0.4.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.17.1)\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (1.74.0)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow==2.17.1)\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: keras>=3.2.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow==2.17.1) (3.11.3)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from tensorflow==2.17.1)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow==2.17.1) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow==2.17.1) (14.1.0)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow==2.17.1) (0.1.0)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.12/site-packages (from keras>=3.2.0->tensorflow==2.17.1) (0.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.1) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow==2.17.1) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.1) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.1) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.18,>=2.17->tensorflow==2.17.1) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow==2.17.1) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow==2.17.1) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.2.0->tensorflow==2.17.1) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow==2.17.1) (0.1.2)\n",
      "Downloading tensorflow-2.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (601.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.4/601.4 MB\u001b[0m \u001b[31m106.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Installing collected packages: protobuf, numpy, tensorboard, tensorflow\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.5\n",
      "    Uninstalling protobuf-5.29.5:\n",
      "      Successfully uninstalled protobuf-5.29.5\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.18.0\n",
      "    Uninstalling tensorboard-2.18.0:\n",
      "      Successfully uninstalled tensorboard-2.18.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-cpu 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.17.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4 protobuf-4.25.8 tensorboard-2.17.1 tensorflow-2.17.1\n",
      "Requirement already satisfied: matplotlib==3.9.2 in /opt/conda/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib==3.9.2) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib==3.9.2) (1.17.0)\n",
      "==== All required libraries are installed =====\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.17.1\n",
    "!pip install matplotlib==3.9.2\n",
    "\n",
    "print(\"==== All required libraries are installed =====\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppress the tensorflow warning messages\n",
    "We use the following code to  suppress the warning messages due to use of CPU architechture for tensoflow.\n",
    "\n",
    "You may want to **comment out** these lines if you are using the GPU architechture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To use Keras, you will also need to install a backend framework – such as TensorFlow.\n",
    "\n",
    "If you install TensorFlow 2.16 or above, it will install Keras by default.\n",
    "\n",
    "We are using the CPU version of tensorflow since we are dealing with smaller datasets. \n",
    "You may install the GPU version of tensorflow on your machine to accelarate the processing of larger datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 10:55:04.956401: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-08-27 10:55:04.976873: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-08-27 10:55:04.982790: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.layers import Layer\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Data Preparation\n",
    "We start by define the sentences and text for translation training\n",
    "Sentence Pairs: Defines a small dataset of English-Spanish sentence pairs.\n",
    "Target Sequences:\n",
    "Prepends \"startseq\" and appends \"endseq\" to each target sentence for the decoder to learn when to start and stop translating.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample parallel sentences (English -> Spanish)\n",
    "input_texts = [\n",
    "    \"Hello.\", \"How are you?\", \"I am learning machine translation.\", \"What is your name?\", \"I love programming.\"\n",
    "]\n",
    "target_texts = [\n",
    "    \"Hola.\", \"¿Cómo estás?\", \"Estoy aprendiendo traducción automática.\", \"¿Cuál es tu nombre?\", \"Me encanta programar.\"\n",
    "]\n",
    "\n",
    "target_texts = [\"startseq \" + x + \" endseq\" for x in target_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, we convert the text from the sentences to tokens and create a vocabulary\n",
    "Tokenization: Uses Tokenizer to convert words into numerical sequences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "input_tokenizer = Tokenizer()\n",
    "input_tokenizer.fit_on_texts(input_texts)\n",
    "input_sequences = input_tokenizer.texts_to_sequences(input_texts)\n",
    "\n",
    "output_tokenizer = Tokenizer()\n",
    "output_tokenizer.fit_on_texts(target_texts)\n",
    "output_sequences = output_tokenizer.texts_to_sequences(target_texts)\n",
    "\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "output_vocab_size = len(output_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now pad the corresponding sentences\n",
    "Padding: Ensures all sequences have the same length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding\n",
    "max_input_length = max([len(seq) for seq in input_sequences])\n",
    "max_output_length = max([len(seq) for seq in output_sequences])\n",
    "\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_input_length, padding='post')\n",
    "output_sequences = pad_sequences(output_sequences, maxlen=max_output_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the target data for training\n",
    "decoder_input_data = output_sequences[:, :-1]\n",
    "decoder_output_data = output_sequences[:, 1:]\n",
    "\n",
    "# Convert to one-hot\n",
    "decoder_output_data = np.array([np.eye(output_vocab_size)[seq] for seq in decoder_output_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Self-Attention Layer\n",
    "Self-attention is a mechanism that allows a model to **focus on relevant parts of the input sequence** while processing each word. This is particularly useful in:\n",
    "1) Machine Translation (e.g., aligning words correctly)\n",
    "2) Text Summarization\n",
    "3) Speech Recognition\n",
    "4) Image Processing (Vision Transformers)\n",
    "In this implementation, self-attention is used for text based sequence-to-sequence modeling.\n",
    "\n",
    "\n",
    "Self-Attention works for a given an input sequence by computing a weighted representation of all words for each position. It does so using three key components:\n",
    "\n",
    "1. Query **(Q)**, Key **(K)**, and Value **(V)** Matrices\n",
    "For each word (token) in a sequence:\n",
    "\n",
    "Query (Q): What this word is looking for.\n",
    "Key (K): What this word represents.\n",
    "Value (V): The actual information in the word.\n",
    "\n",
    "2. Compute **Attention Scores**\n",
    "Next, we **calculate the similarity between each query and key** using dot-product attention:\n",
    "Each word in a sequence attends to every other word based on these scores.\n",
    "\n",
    "3. Apply **Scaling & Softmax**\n",
    "Since dot-product values can be large, we scale them. \n",
    "Next, Applying softmax converts scores into attention weights:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Attention class\n",
    "In this implementation of self-attention layer:\n",
    "1. We first initialize the weights in the **build** method, where:\n",
    "    1. **self.Wq**, **self.Wk**, **self.Wv** are the trainable weight matrices.\n",
    "    2. Their **shape is (feature_dim, feature_dim)**, meaning they transform input features into Q, K, and V representations.\n",
    "2. Applying Attention using **call** method. The **call()** method:\n",
    "   1. Computes **Q, K, V** by multiplying inputs (encoder/decoder output) with their respective weight matrices.\n",
    "   2. Computes **dot-product attention scores** using K.batch_dot(q, k, axes=[2, 2]), resulting in a (batch_size, seq_len, seq_len) matrix.\n",
    "   3. **Scales** the scores to avoid large values.\n",
    "   4. Applies **softmax** to normalize the attention scores.\n",
    "   5. **Multiplies attention weights with V** to get the final output.\n",
    "3. The **compute_output_shape** method defines the shape of the output tensor after the layer processes an input.\n",
    "    1. The output shape of the Self-Attention layer **remains the same** as the input shape.\n",
    "    2. The attention mechanism **transforms** the input but does not change its dimensions.4\n",
    "    3. If the attention layer changed the shape, you would modify compute_output_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Self-Attention Layer\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='glorot_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Model Architecture\n",
    "The model follows an Encoder-Decoder structure:\n",
    "\n",
    "### Encoder:\n",
    "1) Takes input sentences (padded and tokenized).\n",
    "2) Uses an Embedding layer (word representations) + LSTM (to process sequences).\n",
    "    1. The LSTMs are used as the **help process variable-length input sentences** and generate meaningful translations.\n",
    "4) Outputs context vectors (hidden & cell states).\n",
    "\n",
    "### Attention Layer\n",
    "1) Applied to both the encoder and decoder outputs.\n",
    "2) Helps the decoder focus on relevant words during translation.\n",
    "\n",
    "### Decoder\n",
    "1) Receives target sequences (shifted one step ahead).\n",
    "2) Uses an LSTM with encoder states as initial states.\n",
    "3) Applies self-attention for better learning.\n",
    "4) Uses a Dense layer (Softmax) to predict the next word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,352</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)         │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],       │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">196,608</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SelfAttention</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,369</span> │ self_attention_1… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,096\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m4,352\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)         │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m),  │    \u001b[38;5;34m525,312\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],       │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ self_attention_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │    \u001b[38;5;34m196,608\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mSelfAttention\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m17\u001b[0m)     │      \u001b[38;5;34m4,369\u001b[0m │ self_attention_1… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,260,049</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,260,049\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,260,049</span> (4.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,260,049\u001b[0m (4.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Attention Mechanism\n",
    "attention_layer = SelfAttention()(encoder_outputs)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,))\n",
    "decoder_embedding = Embedding(output_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_attention = SelfAttention()(decoder_outputs)  # Apply attention\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_attention)\n",
    "\n",
    "# Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Training the Model\n",
    "Uses categorical_crossentropy as the loss function since output words are one-hot encoded.\n",
    "Trains using Adam optimizer for 100 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step - accuracy: 0.0800 - loss: 2.8311\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.3200 - loss: 2.7950\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.3200 - loss: 2.7530\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.3200 - loss: 2.6956\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.2800 - loss: 2.6136\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.2800 - loss: 2.5003\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.2800 - loss: 2.3673\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.2800 - loss: 2.3036\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.2800 - loss: 2.3579\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.2800 - loss: 2.3005\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.3200 - loss: 2.2190\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.3200 - loss: 2.1673\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.3200 - loss: 2.1349\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.3200 - loss: 2.1005\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.3200 - loss: 2.0527\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.3200 - loss: 1.9927\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.3200 - loss: 1.9319\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.3200 - loss: 1.8853\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.3200 - loss: 1.8527\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.3200 - loss: 1.8133\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.3200 - loss: 1.7588\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.3200 - loss: 1.7040\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.3200 - loss: 1.6626\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.3200 - loss: 1.6262\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.3200 - loss: 1.5847\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.3200 - loss: 1.5636\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.3200 - loss: 1.5484\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.3200 - loss: 1.5343\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.3200 - loss: 1.5217\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.3200 - loss: 1.5117\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.3200 - loss: 1.4967\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.3200 - loss: 1.4867\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.2800 - loss: 1.4668\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.3200 - loss: 1.4594\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.3200 - loss: 1.4472\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.3200 - loss: 1.4303\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.3200 - loss: 1.4341\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.3600 - loss: 1.4045\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.3600 - loss: 1.3792\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.3600 - loss: 1.3657\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.3200 - loss: 1.3411\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.3600 - loss: 1.3103\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.3600 - loss: 1.2658\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.4400 - loss: 1.2234\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.4400 - loss: 1.1922\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.4400 - loss: 1.1601\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.4800 - loss: 1.1180\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.5200 - loss: 1.0836\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.6000 - loss: 1.0423\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.6400 - loss: 1.0052\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.5600 - loss: 0.9759\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.4800 - loss: 1.0101\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.4800 - loss: 1.0622\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.5200 - loss: 1.0351\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.6000 - loss: 0.9966\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.5200 - loss: 0.9870\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.5200 - loss: 1.0208\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.5200 - loss: 1.1633\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.5200 - loss: 0.9116\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.4800 - loss: 0.9475\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.5600 - loss: 0.9125\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.7600 - loss: 0.9063\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.5200 - loss: 1.0120\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.6400 - loss: 0.8348\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.5600 - loss: 0.8705\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.6800 - loss: 0.7913\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.6800 - loss: 0.7818\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.6000 - loss: 0.7823\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.7600 - loss: 0.7502\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.7200 - loss: 0.7271\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.6400 - loss: 0.7160\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.6800 - loss: 0.7019\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.7200 - loss: 0.6868\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.8000 - loss: 0.6791\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.7600 - loss: 0.6524\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7600 - loss: 0.6358\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.7600 - loss: 0.6215\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.7600 - loss: 0.6139\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.8000 - loss: 0.5999\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.8400 - loss: 0.5939\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8400 - loss: 0.5799\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.8400 - loss: 0.5622\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.8000 - loss: 0.5548\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.8400 - loss: 0.5405\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.8000 - loss: 0.5339\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.8000 - loss: 0.5228\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.8400 - loss: 0.5079\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8400 - loss: 0.4940\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.9200 - loss: 0.4781\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.9200 - loss: 0.4643\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9200 - loss: 0.4483\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.8800 - loss: 0.4334\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8800 - loss: 0.4180\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9200 - loss: 0.4024\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.9200 - loss: 0.3883\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9600 - loss: 0.3729\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9600 - loss: 0.3595\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9600 - loss: 0.3461\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9600 - loss: 0.3336\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.9600 - loss: 0.3216\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Train the Model\n",
    "history_glorot_adam = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Plotting the training loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABRA0lEQVR4nO3deVhU9f4H8PcsMOz7jmzigoKigiiaqWkueUvNNtNEW03t6rV+la1mi3Vtz66WpZRrWi7ljvuGIgguCKjJJjAgsm8DzJzfH+gUgQg4cGaG9+t55nmcs82H0xPz5nu+i0QQBAFERERERkIqdgFEREREusRwQ0REREaF4YaIiIiMCsMNERERGRWGGyIiIjIqDDdERERkVBhuiIiIyKgw3BAREZFRYbghIiIio8JwQ0Rtbvr06fD19W3VuQsXLoREItFtQURk1BhuiDowiUTSrNehQ4fELlUU06dPh5WVldhlEFELSbi2FFHHtWbNmnrvf/75Z0RFRWH16tX1tt9///1wdXVt9efU1NRAo9FAoVC0+Nza2lrU1tbCzMys1Z/fWtOnT8evv/6KsrKydv9sImo9udgFEJF4pk6dWu/9yZMnERUV1WD7P1VUVMDCwqLZn2NiYtKq+gBALpdDLuevKiJqPj6WIqImDRs2DEFBQYiLi8O9994LCwsLvPHGGwCAbdu2Ydy4cfDw8IBCoYC/vz/ef/99qNXqetf4Z5+btLQ0SCQSfPrpp/j+++/h7+8PhUKB/v374/Tp0/XObazPjUQiwZw5c7B161YEBQVBoVAgMDAQu3fvblD/oUOHEBoaCjMzM/j7++O7777TeT+eTZs2ISQkBObm5nBycsLUqVORlZVV7xilUokZM2agU6dOUCgUcHd3x/jx45GWlqY9JjY2FqNHj4aTkxPMzc3h5+eHp59+Wmd1EnUU/HOIiO7oxo0bGDt2LJ544glMnTpV+4gqMjISVlZWmD9/PqysrHDgwAG88847KCkpwZIlS+543XXr1qG0tBQvvPACJBIJ/vvf/+Lhhx/G1atX79jac+zYMWzevBmzZs2CtbU1vv76a0yaNAkZGRlwdHQEAMTHx2PMmDFwd3fHe++9B7VajUWLFsHZ2fnub8pNkZGRmDFjBvr374/FixcjNzcXX331FY4fP474+HjY2dkBACZNmoTExES89NJL8PX1RV5eHqKiopCRkaF9P2rUKDg7O+P111+HnZ0d0tLSsHnzZp3VStRhCEREN82ePVv456+FoUOHCgCE5cuXNzi+oqKiwbYXXnhBsLCwEKqqqrTbIiIiBB8fH+371NRUAYDg6OgoFBQUaLdv27ZNACD88ccf2m3vvvtug5oACKampsKVK1e0286ePSsAEL755hvttgcffFCwsLAQsrKytNsuX74syOXyBtdsTEREhGBpaXnb/dXV1YKLi4sQFBQkVFZWardv375dACC88847giAIQmFhoQBAWLJkyW2vtWXLFgGAcPr06TvWRURN42MpIrojhUKBGTNmNNhubm6u/XdpaSny8/MxZMgQVFRUIDk5+Y7Xffzxx2Fvb699P2TIEADA1atX73juyJEj4e/vr33fu3dv2NjYaM9Vq9XYt28fJkyYAA8PD+1xXbp0wdixY+94/eaIjY1FXl4eZs2aVa/D87hx4xAQEIAdO3YAqLtPpqamOHToEAoLCxu91q0Wnu3bt6OmpkYn9RF1VAw3RHRHnp6eMDU1bbA9MTEREydOhK2tLWxsbODs7KztjFxcXHzH63p7e9d7fyvo3C4ANHXurfNvnZuXl4fKykp06dKlwXGNbWuN9PR0AED37t0b7AsICNDuVygU+OSTT7Br1y64urri3nvvxX//+18olUrt8UOHDsWkSZPw3nvvwcnJCePHj8eqVaugUql0UitRR8JwQ0R39PcWmluKioowdOhQnD17FosWLcIff/yBqKgofPLJJwAAjUZzx+vKZLJGtwvNmKHibs4Vw7x583Dp0iUsXrwYZmZmePvtt9GjRw/Ex8cDqOsk/euvvyI6Ohpz5sxBVlYWnn76aYSEhHAoOlELMdwQUascOnQIN27cQGRkJObOnYt//etfGDlyZL3HTGJycXGBmZkZrly50mBfY9taw8fHBwCQkpLSYF9KSop2/y3+/v54+eWXsXfvXly4cAHV1dX47LPP6h0zcOBAfPjhh4iNjcXatWuRmJiIDRs26KReoo6C4YaIWuVWy8nfW0qqq6vxv//9T6yS6pHJZBg5ciS2bt2K7Oxs7fYrV65g165dOvmM0NBQuLi4YPny5fUeH+3atQtJSUkYN24cgLp5gaqqquqd6+/vD2tra+15hYWFDVqd+vTpAwB8NEXUQhwKTkStMmjQINjb2yMiIgL//ve/IZFIsHr1ar16LLRw4ULs3bsXgwcPxosvvgi1Wo2lS5ciKCgICQkJzbpGTU0NPvjggwbbHRwcMGvWLHzyySeYMWMGhg4dismTJ2uHgvv6+uI///kPAODSpUsYMWIEHnvsMfTs2RNyuRxbtmxBbm4unnjiCQDATz/9hP/973+YOHEi/P39UVpaihUrVsDGxgYPPPCAzu4JUUfAcENEreLo6Ijt27fj5ZdfxltvvQV7e3tMnToVI0aMwOjRo8UuDwAQEhKCXbt24ZVXXsHbb78NLy8vLFq0CElJSc0azQXUtUa9/fbbDbb7+/tj1qxZmD59OiwsLPDxxx/jtddeg6WlJSZOnIhPPvlEOwLKy8sLkydPxv79+7F69WrI5XIEBARg48aNmDRpEoC6DsUxMTHYsGEDcnNzYWtri7CwMKxduxZ+fn46uydEHQHXliKiDmfChAlITEzE5cuXxS6FiNoA+9wQkVGrrKys9/7y5cvYuXMnhg0bJk5BRNTm2HJDREbN3d0d06dPR+fOnZGeno5ly5ZBpVIhPj4eXbt2Fbs8ImoD7HNDREZtzJgxWL9+PZRKJRQKBcLDw/HRRx8x2BAZMbbcEBERkVFhnxsiIiIyKgw3REREZFQ6XJ8bjUaD7OxsWFtbQyKRiF0OERERNYMgCCgtLYWHhwek0qbbZjpcuMnOzoaXl5fYZRAREVErZGZmolOnTk0e0+HCjbW1NYC6m2NjYyNyNURERNQcJSUl8PLy0n6PN6XDhZtbj6JsbGwYboiIiAxMc7qUsEMxERERGRWGGyIiIjIqDDdERERkVBhuiIiIyKgw3BAREZFRYbghIiIio8JwQ0REREaF4YaIiIiMCsMNERERGRWGGyIiIjIqDDdERERkVBhuiIiIyKgw3OhQXHoBbpSpxC6DiIioQ2O40ZEjl67jyRWnELEqBiVVNWKXQ0RE1GEx3OiIp705rBRyXMgqwTORp1FZrRa7JCIiog6J4UZH/J2t8PMzYbA2k+N0WiGeXx0LVS0DDhERUXtjuNGhQA9bRM7oD3MTGY5ezsfc9QmoVWvELouIiKhDYbjRsRAfB6yYFgpTmRS7E5V47bfz0GgEscsiIiLqMBhu2sA9XZ3wzZN9IZNK8NuZa/g86pLYJREREXUYDDdtZHSgGz6Z1BsAsPTgFew8nyNyRURERB0Dw00beiSkE569xw8A8PLGs0jKKRG5IiIiIuPHcNPGXh8bgCFdnVBZo8ZzP8eioLxa7JKIiIiMGsNNG5PLpPhmcl94O1jgWmEl5qw7wxFUREREbYjhph3YWZhixbRQWJjKcOLPG/hoZ7LYJRERERkthpt20t3NGp8/FgwAWHk8FXHphSJXREREZJwYbtrRmCB3PBrSCQCw8PdEqDn/DRERkc4x3LSzV8cEwNpMjvNZxfjldKbY5RARERkdhpt25mytwH9GdgMALNmTjKIKjp4iIiLSJYYbEUwL90F3V2sUVtTgs72cvZiIiEiXGG5EIJdJsfChQADA2lPpSMwuFrkiIiIi48FwI5Jwf0c8GOwBjQC8uy0RgsDOxURERLrAcCOiNx4IgLmJDLHphfj9bLbY5RARERkFhhsRudua48Vh/gCAH4+lilwNERGRcWC4EdnUgT4wlUtx7loxzmYWiV0OERGRwWO4EZmDpSn+1csdALD6ZLrI1RARERk+hhs9MDXcBwDwx9lsFHLVcCIiorvCcKMH+nrZIdDDBqpaDTbFcdZiIiKiu8FwowckEgmeGljXerPmZAY0XHOKiIio1Rhu9MT4Pp6wNpMjo6ACRy5fF7scIiIig8VwoyfMTWV4NMQLALCGHYuJiIhajeFGj0wZ6A0A2J+ch8yCCpGrISIiMkwMN3rE39kK93RxgiAA62IyxC6HiIjIIDHc6JmpNzsW/3I6E9W1GpGrISIiMjwMN3pmZA8XOFmZoqC8GjGpBWKXQ0REZHAYbvSMXCbFfQEuAIB9SbkiV0NERGR4GG700IgergCA/cm5EATOeUNERNQSDDd66J4uTjCVS5FZUInLeWVil0NERGRQGG70kKVCjvDOjgCA/Ul5IldDRERkWBhu9NTIHnX9bvaz3w0REVGLMNzoqftu9rs5k1GIAq4UTkRE1GwMN3rK084cPdxtoBGAg8l8NEVERNRcDDd6TPtoKpmPpoiIiJqL4UaP3RoSfuRSPmcrJiIiaiaGGz3W29MWztYKlKlqcSr1htjlEBERGQRRw83ixYvRv39/WFtbw8XFBRMmTEBKSkqT50RGRkIikdR7mZmZtVPF7UsqleC+7rdGTbHfDRERUXOIGm4OHz6M2bNn4+TJk4iKikJNTQ1GjRqF8vLyJs+zsbFBTk6O9pWent5OFbe/ET3+WoqBsxUTERHdmVzMD9+9e3e995GRkXBxcUFcXBzuvffe254nkUjg5ubW1uXphXu61s1WfK2wbrbibq7WYpdERESk1/Sqz01xcTEAwMHBocnjysrK4OPjAy8vL4wfPx6JiYm3PValUqGkpKTey5BYmMoxyL9utmIupElERHRnehNuNBoN5s2bh8GDByMoKOi2x3Xv3h0rV67Etm3bsGbNGmg0GgwaNAjXrl1r9PjFixfD1tZW+/Ly8mqrH6HNjLi5SviRS9dFroSIiEj/SQQ96cjx4osvYteuXTh27Bg6derU7PNqamrQo0cPTJ48Ge+//36D/SqVCiqVSvu+pKQEXl5eKC4uho2NjU5qb2t/Xi/DiM8Ow1Quxbl3R8HMRCZ2SURERO2qpKQEtra2zfr+FrXPzS1z5szB9u3bceTIkRYFGwAwMTFB3759ceXKlUb3KxQKKBQKXZQpms5OlnCxViCvVIUz6YUY1MVJ7JKIiIj0lqiPpQRBwJw5c7BlyxYcOHAAfn5+Lb6GWq3G+fPn4e7u3gYV6geJRKLtdxN9lfPdEBERNUXUcDN79mysWbMG69atg7W1NZRKJZRKJSorK7XHTJs2DQsWLNC+X7RoEfbu3YurV6/izJkzmDp1KtLT0/Hss8+K8SO0m/Cb4ebEnww3RERETRH1sdSyZcsAAMOGDau3fdWqVZg+fToAICMjA1LpXxmssLAQzz33HJRKJezt7RESEoITJ06gZ8+e7VW2KAb51z2KOptZhHJVLSwVevFEkYiISO/oTYfi9tKSDkn6ZvDHB5BVVImfng7D0G7OYpdDRETUblry/a03Q8HpzgZpH03li1wJERGR/mK4MSC3+t2cZL8bIiKi22K4MSC3ws35rGKUVNWIXA0REZF+YrgxIO625vBzsoRGAGKuFohdDhERkV5iuDEwHBJORETUNIYbAxPemZP5ERERNYXhxsAMvBluknJKUFBeLXI1RERE+ofhxsA4WyvQzdUKAHCKrTdEREQNMNwYoFuzFbPfDRERUUMMNwZoIPvdEBER3RbDjQEa2NkBEglwJa8MWUWVdz6BiIioA2G4MUB2FqYI83UAAPzv4JXbHrctIQsvrY9HUQU7HhMRUcfBcGOg5t/fDQCw4XQmUvPLG+y/er0M//frOfxxNhsf70pu7/KIiIhEw3BjoAZ0dsTw7s5QawR8ujel3j5BEPDmlguortUAAH6JzcTZzCIRqiQiImp/DDcG7P9GB0AiAXacy8H5a8Xa7ZvPZCH66g2YmUhxbzdnCALwzu+J0GgEEaslIiJqHww3Bqynhw3GB3sAAP67p+7RU0F5NT7YcREAMHdEN3z6SG9YKeQ4m1mEX+OuiVYrERFRe2G4MXDz7+8OE5kERy/n4/iVfHy0MwmFFTXo7mqNZ4f4wcXGDHNHdAUAfLI7GcWVXE2ciIiMG8ONgfN2tMCTYd4AgFd/Padtnfno4V4wkdX9550+2BddXKxwo7waX0RdEq1WIiKi9sBwYwTm3NcVFqYy7Zw3UwZ4I8THXrvfRCbFwgcDAQCrT6YjWVkiSp1ERETtgeHGCDhbK/DskM7af786JqDBMfd0dcLYIDeoNQI+2J7U3iUSERG1G7nYBZBuzBrmD4Vcinu7OsPW3KTRY954oAf2XszFsSv5SFGWorubdTtXSURE1PbYcmMkzExkmD28C3p1sr3tMV4OFri/hysAYPXJtHaqjIiIqH0x3HQw08J9AABbzmShtIojp4iIyPgw3HQw4f6O6OJihfJqNTafyRK7HCIiIp1juOlgJBIJnhpY13qz+mQ6BIGzFhMRkXFhuOmAHu7nCUtTGa7klSH66g2xyyEiItIphpsOyNrMBBP7eQIAVkeni1wNERGRbjHcdFBPDfQFAOy9mIuc4kpxiyEiItIhhpsOqrubNcL8HKDWCFh/KkPscoiIiHSG4aYDuzUsfF1MJqprNSJXQ0REpBsMNx3Y6EA3uFgrkF+mwpb4a2KXQ0REpBMMNx2YiUyKZ4f4AQA+3JGEvJIqkSsiIiK6eww3HdzTg/3Qy9MWJVW1eHPrBc57Q0REBo/hpoOTy6RY8mhvmMgkiLqYiz/O5YhdEhER0V1huCEEuNlg9vAuAICFvyfiRplK5IqIiIhaj+GGAACzhnVBgJs1Csqr8e7viWKXQ0RE1GoMNwQAMJVLseSRYMikEmw/l4PdF5Ril0RERNQqDDek1auTLV64tzMA4PXN53D+WrHIFREREbUcww3V8+8RXdHHyw5FFTV4csVJxKYViF0SERFRizDcUD1mJjKseXYAwvwcUKqqxVM/xuDY5XyxyyIiImo2hhtqwEohx08zwjC0mzMqa9R4OvI09l3MFbssIiKiZmG4oUaZm8rw/bQQjA50RbVag5lr4rDzPOfAISIi/cdwQ7elkMvw7ZP9MKGPB2o1Al5aH4/dFxhwiIhIvzHcUJPkMik+e6wPHu7rCbVGwJx18diTyGHiRESkvxhu6I5kUgmWPBqsbcGZs+4M++AQEZHeYrihZpFJJfj00WA8GOyBGrWAF9fGYX8SAw4REekfhhtqNrlMii8eC8a43u43A84ZpChLxS6LiIioHoYbahG5TIqvHu+Dod2cUV2rwb/Xx6OqRi12WURERFoMN9RicpkUnz4aDCcrU6TkluKT3clil0RERKTFcEOt4mytwJJHggEAq46n4VBKnsgVERER1WG4oVYbHuCC6YN8AQCvbDqH/DKVuAURERGB4Ybu0utjA9DN1Qr5ZSq89us5CIIgdklERNTBMdzQXTEzkeGrJ/rCVCbF/uQ8rIvJELskIiLq4Bhu6K71cLfBq2O6AwCW7ElBcUWNyBUREVFHxnBDOjF9kC+6uVqhqKIGX+2/LHY5RETUgTHckE7IZVK8Oa4nAODn6DRcvV4mckVERNRRiRpuFi9ejP79+8Pa2houLi6YMGECUlJS7njepk2bEBAQADMzM/Tq1Qs7d+5sh2rpToZ2c8aw7s6o1Qj4aCfnviEiInGIGm4OHz6M2bNn4+TJk4iKikJNTQ1GjRqF8vLy255z4sQJTJ48Gc888wzi4+MxYcIETJgwARcuXGjHyul23hrXAzKpBPuScnHiSr7Y5RARUQckEfRo7O7169fh4uKCw4cP49577230mMcffxzl5eXYvn27dtvAgQPRp08fLF++/I6fUVJSAltbWxQXF8PGxkZntdNf3t12AT9FpyPAzRo7/j0EMqlE7JKIiMjAteT7W6/63BQXFwMAHBwcbntMdHQ0Ro4cWW/b6NGjER0d3ejxKpUKJSUl9V7UtuaN7AYbMzmSlaXYFJspdjlERNTB6E240Wg0mDdvHgYPHoygoKDbHqdUKuHq6lpvm6urK5RKZaPHL168GLa2ttqXl5eXTuumhuwtTfHvEV0BAJ/uvYQyVa3IFRERUUeiN+Fm9uzZuHDhAjZs2KDT6y5YsADFxcXaV2YmWxLaw7RwX/g5WSK/TIXlh/4UuxwiIupA9CLczJkzB9u3b8fBgwfRqVOnJo91c3NDbm5uvW25ublwc3Nr9HiFQgEbG5t6L2p7pnIpXh8bAABYcfQqsosqRa6IiIg6ClHDjSAImDNnDrZs2YIDBw7Az8/vjueEh4dj//799bZFRUUhPDy8rcqkVhrV0xVhfg5Q1WqwZM+dh/gTERHpgqjhZvbs2VizZg3WrVsHa2trKJVKKJVKVFb+9Vf+tGnTsGDBAu37uXPnYvfu3fjss8+QnJyMhQsXIjY2FnPmzBHjR6AmSCQSvDWuBwBgS3wWzl0rErcgIiLqEEQNN8uWLUNxcTGGDRsGd3d37euXX37RHpORkYGcnBzt+0GDBmHdunX4/vvvERwcjF9//RVbt25tshMyiad3JztM7OsJAPhgRxJXDSciojanV/PctAfOc9P+sosqMfzTQ1DVavDdUyEYHdh4/ygiIqLbMdh5bsg4ediZ47khnQEAi3cmobpWI3JFRERkzBhuqF3MHOYPJysF0m5U4OfoNLHLISIiI8ZwQ+3CSiHHy6O6AQA+3ZuCy7mlIldERETGiuGG2s3joV4Y0tUJVTUavLQ+HlU1arFLIiIiI8RwQ+1GKpXgs8eC4WRlimRlKT7amSR2SUREZIQYbqhduVib4bPH+gAAfo5Ox57ExtcEIyIiai2GG2p3Q7s54/l760ZPvfrrOS7NQEREOsVwQ6J4ZVR3BHeyRXFlDeZtSECtmsPDiYhINxhuSBSmcim+ntwXVgo5YtIK8NL6eM5/Q0REOsFwQ6LxcbTE15P7wFQmxa4LSrywOpYjqIiI6K4x3JCo7gtwxY/TQ2FmIsXBlOuYseo0ylW1YpdFREQGjOGGRDekqzN+mhEGS1MZoq/ewLSVMSiurBG7LCIiMlAMN6QXBnR2xNrnBsLGTI649EJErIxBZTUfURERUcsx3JDe6ONlhw3Ph8POwgQJmUWYvzEBGk2HWrSeiIh0gOGG9EpPDxt8/1SotpPxx7uTxS6JiIgMDMMN6Z0wPwcsebQ3AOD7I1ex+mS6yBUREZEhYbghvTS+jydeubmK+LvbLuBgcp7IFRERkaFguCG9NXt4FzwW2gkaAZi97gwu5ZaKXRIRERkAhhvSWxKJBB9O7IVB/o6oqFbjtd/OsYMxERHdEcMN6TUTmRSfPRYMS1MZ4jOKsP50htglERGRnmO4Ib3nbmuOV0Z3BwB8vCsZeaVVIldERET6jOGGDMK0cF/08rRFaVUt3t+eJHY5RESkxxhuyCDIpBJ8NLEXpBLgj7PZOHzputglERGRnmK4IYPRq5Mtpg/yAwC8tfU8l2cgIqJGMdyQQZk/qhvcbc2QWVCJbw5cFrscIiLSQww3ZFCsFHIsfCgQQN3sxZz7hoiI/onhhgzO6EA3jOzhilqNgDe3nOfcN0REVA/DDRmk98YHwsJUhtNphdgYmyl2OUREpEcYbsggedqZ4z8j69aeWrwrGfllKpErIiIifcFwQwZrxmBf9HC3QXFlDT7awblviIioDsMNGSy5TIqPJgZBIgE2x2fhxJV8sUsiIiI9wHBDBq2vtz2mDvABALy19QJUtZz7hoioo2O4IYP3f2O6w9lagav55fhkV4rY5RARkcgYbsjg2ZiZ4IMJQQCAlcdTsYmjp4iIOjSGGzIKowPd8O8RXQEAb265gLj0QpErIiIisTDckNGYN6IrRge6olqtwQur45BTXCl2SUREJAKGGzIaUqkEnz/WBwFu1sgvU+H5n+O4uCYRUQfEcENGxVIhx4ppoXCwNMX5rGL8369nuTwDEVEH06pwk5mZiWvXrmnfx8TEYN68efj+++91VhhRa3k5WGDZlH6QSyXYfi4Hi7ZfhCAw4BARdRStCjdPPvkkDh48CABQKpW4//77ERMTgzfffBOLFi3SaYFErTGgsyM+fTQYEgkQeSINX+y7LHZJRETUTloVbi5cuICwsDAAwMaNGxEUFIQTJ05g7dq1iIyM1GV9RK02oa8nFj0UCAD4ev9l/HD0qsgVERFRe2hVuKmpqYFCoQAA7Nu3Dw899BAAICAgADk5ObqrjuguPRXui/8b3R0A8MGOJGw8zTlwiIiMXavCTWBgIJYvX46jR48iKioKY8aMAQBkZ2fD0dFRpwUS3a1Zw/zxwr2dAQCvbz6H3ReUIldERERtqVXh5pNPPsF3332HYcOGYfLkyQgODgYA/P7779rHVUT6QiKR4PWxAZgc5gWNAPznlwRczC4RuywiImojEqGVw0jUajVKSkpgb2+v3ZaWlgYLCwu4uLjorEBdKykpga2tLYqLi2FjYyN2OdSOatUazIg8jaOX8+FpZ47f5wyGo5VC7LKIiKgZWvL93aqWm8rKSqhUKm2wSU9Px5dffomUlBS9DjbUscllUiyd3A++jhbIKqrEi2vPoLpWI3ZZRESkY60KN+PHj8fPP/8MACgqKsKAAQPw2WefYcKECVi2bJlOCyTSJVsLE/wQEQorhRwxqQVY+Eei2CUREZGOtSrcnDlzBkOGDAEA/Prrr3B1dUV6ejp+/vlnfP311zotkEjXurhY4+vJfSCRAOtOZWD1yXSxSyIiIh1qVbipqKiAtbU1AGDv3r14+OGHIZVKMXDgQKSn84uC9N99Aa54dXQAAOCdbRfwzrYLKKmqEbkqIiLShVaFmy5dumDr1q3IzMzEnj17MGrUKABAXl4eO+mSwZg5tDOmhftAEICfo9Mx4rPD+ONsNpdqICIycK0KN++88w5eeeUV+Pr6IiwsDOHh4QDqWnH69u2r0wKJ2opEIsGi8UFY++wA+DlZ4nqpCi+tj8e0lTG4lFsqdnlERNRKrR4KrlQqkZOTg+DgYEildRkpJiYGNjY2CAgI0GmRusSh4NSYqho1vjt8Fd8euqIdQTWsuzOeG9IZg/wdIZFIRK6QiKhja8n3d6vDzS23Vgfv1KnT3Vym3TDcUFNS88vxya5k7LmoxK3/M3q42+DZe/wwrrc7zExk4hZIRNRBtfk8NxqNBosWLYKtrS18fHzg4+MDOzs7vP/++9BoOG8IGS4/J0ssfyoEB18ehmnhPjA3kSEppwQvbzqLQR8fwMe7kpFZUCF2mURE1IRWtdwsWLAAP/74I9577z0MHjwYAHDs2DEsXLgQzz33HD788EOdF6orbLmhliiqqMbaUxlYczIdOcVVAACJBBjWzRlPhHljeHcXmMpb9TcCERG1QJs/lvLw8MDy5cu1q4Hfsm3bNsyaNQtZWVktvWS7Ybih1qhVa3AgOQ+rT6bj6OV87XYHS1M8FOyBSf06IcjThn1ziIjaSJs/liooKGi003BAQAAKCgqafZ0jR47gwQcfhIeHByQSCbZu3drk8YcOHYJEImnwUiq5yjO1LblMilGBblj9zAAcfGUYnr+3M5ysFCgor0bkiTQ8uPQYRn1xBEv2JCMuvRBqDYeTExGJRd6ak4KDg7F06dIGsxEvXboUvXv3bvZ1ysvLERwcjKeffhoPP/xws89LSUmpl9q4nhW1Jz8nS7zxQA+8Oro7jl7Ox29nrmHvxVxczivD5bwyfHvwTzhYmmJYd2eM6+WO4d1dIJWyRYeIqL20Ktz897//xbhx47Bv3z7tHDfR0dHIzMzEzp07m32dsWPHYuzYsS3+fBcXF9jZ2bX4PCJdksukGB7gguEBLiiurMH+pFwcSM7D4UvXUVBejc1nsrD5TBZ8HS0wY7AfHgnpBEtFq/6XIyKiFmjVY6mhQ4fi0qVLmDhxIoqKilBUVISHH34YiYmJWL16ta5rbKBPnz5wd3fH/fffj+PHjzd5rEqlQklJSb0Xka7Zmpvg4X6dsPTJfjjz9v1Y/9xAzBjsC2szOdJuVODd3xMRvng/Fu9MwvlrxdDwsRURUZu563lu/u7s2bPo168f1Gp1ywuRSLBlyxZMmDDhtsekpKTg0KFDCA0NhUqlwg8//IDVq1fj1KlT6NevX6PnLFy4EO+9916D7exQTO2hXFWL385cw8pjqUi78dcQcmdrBYZ3d8Z9AS4Y0tWZLTpERHfQrpP4/V1bh5vGDB06FN7e3rdtMVKpVFCpVNr3JSUl8PLyYrihdqXRCDiQnIeNsZk4diUfFdV//T9ia26Cl0d1w5Nh3pDLOKyciKgxLQk3Bv/nYlhYGI4dO3bb/QqFAgqFoh0rImpIKpVgZE9XjOzpClWtGjGpBTiQnId9SbnILKjEO9sSse5UBt59MBDh/o5il0tEZNAM/s/EhIQEuLu7i10GUbMp5DIM6eqMdx8MxMGXh+H98YGwNTdBsrIUk1ecxOy1Z3D40nUUV9SIXSoRkUFqUcvNnYZrFxUVtejDy8rKcOXKFe371NRUJCQkwMHBAd7e3liwYAGysrLw888/AwC+/PJL+Pn5ITAwEFVVVfjhhx9w4MAB7N27t0WfS6Qv5DIpngr3xb96e+DzqEtYeyodO87nYMf5HABAZ2dL9PGywwA/B4wOdIOdhanIFRMR6b8WhRtbW9s77p82bVqzrxcbG4vhw4dr38+fPx8AEBERgcjISOTk5CAjI0O7v7q6Gi+//DKysrJgYWGB3r17Y9++ffWuQWSI7C1N8f6EIEwO88YPx64iPqMIqfnluHq97rX5TBbe2noBw7u7YEJfT9wX4MJFPImIbkOnHYoNAZdfIENRWF6NhGtFiE8vRFRSHpJy/prGwNpMjsdDvfD80M5wsTYTsUoiovYh2mgpQ8BwQ4YqWVmCrfHZ+D0hC9k3F/FUyKWYOtAHLzQSclS1aijkbN0hIuPAcNMEhhsydBqNgMOXr+Pr/ZcRn1EEoC7kjOzpirKqWuQUVyKnuAqlVbUY3MURSyf3g70l++oQkWFjuGkCww0ZC0EQcORyPr7cd0kbchrj52SJyBn94eNo2X7FERHpGMNNExhuyNgIgoBjV/JxNrMILtZmcLczg7utGapqNHhhdRyyiirhYGmKFdNCEeJjL3a5REStwnDTBIYb6kjySqvwTGQszmcVQyGX4svH+2BsL84LRUSGpyXf3wY/iR8R3Z6LtRl+eWEgRvZwgapWg1nrzuCzvSmoVWvELo2IqM0w3BAZOQtTOb57KhTTB/lCEIBvDlzBkz+cgvLmiCsiImPDcEPUAcikEix8KBBfPdEHlqYyxKQWYOxXR3AgOVfs0oiIdI7hhqgDGd/HE9v/PQSBHjYorKjB05GxeP23c/UmCCQiMnTsUEzUAalq1Vi8MxmRJ9K02/p42eHJMG/8K9gdFqYtWpmFiKjNcbRUExhuiP4S/ecNrD6Zhr2JuajV1P0qsFbI8eqY7pg60AcSiUTkComI6jDcNIHhhqih66Uq/HbmGtbHZCD9RgUA4P6ervjvpN6c3ZiI9ALDTRMYbohuT6MRsOpEGj7ZlYxqtQauNgp88XgfDPJ3Ers0IurgOM8NEbWKVCrBM/f4YfOsQejsbIncEhWm/HAKn+9NgUbTof4OIiIDxnBDRA0Eedpi+0v34In+XhAE4OsDV/DyprOo4eR/RGQAGG6IqFEWpnJ8PKk3Pn00GHKpBFvis/DMT7EoV9WKXRoRUZMYboioSY+EdMKKiFCYm8hw5NJ1PPnDKRSUV4tdFhHRbTHcENEdDe/ugnXPDYC9hQnOZhbhkWUncK2wQuyyiIgaxXBDRM3S19sev744CJ525riaX45nf4pFVY1a7LKIiBpguCGiZvN3tsKmmeFwsjJFsrIU725LFLskIqIGGG6IqEU87Mzx1RN9IZEAv8RmYlNsptglERHVw3BDRC02uIsT5o/sBgB4e9sFLrxJRHqF4YaIWmX28C4Y2s0ZVTUazFp7BqVVNWKXREQEgOGGiFpJKpXgi8f7wMPWDKn55Xj9t/PoYKu5EJGeYrgholZzsDTF0in9YCKTYMf5HKw4elXskoiIGG6I6O7087bH2//qCQD4eFcyjly6LnJFRNTRMdwQ0V17aqAPHgvtBI0AvLQ+Huk3ysUuiYg6MIYbIrprEokEi8YHIdjLDsWVNXhhdRzXoCIi0TDcEJFOmJnI8N3UEDhZKZCsLMX//XqWHYyJSBQMN0SkM262Zlg+ta6D8c7zSny29xIDDhG1O4YbItKpUF8HLHwoEACw9OAVvPfHRWg0DDhE1H4YbohI56YM8MG7D9aNoIo8kYb5GxNQo9aIXBURdRQMN0TUJmYM9sOXj/eBXCrB1oRsPPdzLCqruYo4EbU9hhsiajMT+npixbRQmJlIcSjlOqb+eArFFVymgYjaFsMNEbWp4QEuWPPMANiYyRGXXognVpxEfplK7LKIyIgx3BBRmwv1dcDGmeFwslIgKacEjy2PRnZRpdhlEZGRYrghonYR4GaDTTPD4Wlnjqv55Xh0eTRS8zmTMRHpHsMNEbUbPydLbJoZjs5OlsgqqsSjy6ORlFMidlk6F59RiOmrYpBZUCF2KUQdEsMNEbUrDztz/PJCOHq42yC/TIWIlTHILakSuyyd+ubAFRxKuY71MRlil0LUITHcEFG7c7ZWYMNzA9HN1Qp5pSq8sDoOVTXGMUxcoxEQm1YAAEhnyw2RKBhuiEgUthYmWDEtFLbmJkjILMLbWy8YxVINKbmlKKmqWzQ04wbDDZEYGG6ISDQ+jpZY+mRfSCXAprhr+OlEmtgl3bXTN1ttACCDLTdEomC4ISJRDenqjAVjewAA3t+RhBN/5otc0d05lfpXuCmurOGkhUQiYLghItE9O8QPE/t6Qq0RMHvtGaQZ6BBxQRBw+m/hBmDrDZEYGG6ISHQSiQSLH+6FXp62KKyoweQVJw2yv0pGQQXySlUwkUkQ5GkDAEgvMMygRmTIGG6ISC+Ymciwcnp/dHGxQk5xFSavOGlw88TE3Gy16d3JDt1crAEA6QYY0ogMHcMNEekNZ2sF1j03AJ2d6yb5e+J7wwo4tzoT9/d1gJeDBQAYVP1ExoLhhoj0iou1GdY/NxB+N2cxnrziJLIMZB2q02mFAIAwP3v4ONaFG7bcELU/hhsi0juuNnUBx9fRAtcKKzH1h1N6P+oor7QKqfnlkEiAEB8Hbbhhh2Ki9sdwQ0R6yc3WDOufHwhPO3Ok5pdj9rozqFVrxC7rtk6n1rXaBLjZwNbcRPtYKru4EtW1+ls3kTFiuCEiveVua44fIkJhYSrDsSv5+GBHkk6vfzm3VGfLPtzqbxPmaw8AcLZSwNxEBkEArhWy9YaoPTHcEJFe6+Fug88f6wMAiDyRhg06Woxy3akM3P/FEYz96igu55be9fVujZTq7+cAoG54u7cDH00RiYHhhoj03pggN8y/vxsA4O1tF+otcdAa1wor8OGOiwCA1PxyTPj2OHZfyGn19UqqapCkLAEAhPk6aLd7s98NkSgYbojIILx0XxeM6+2OGrWAmavjWj3EWhAELNh8HuXVavTztkN4Z0eUV6sxc80ZLNmTDLWm5Yt3xqUXQhAAH0cLuNiYabf7OHDEFJEYGG6IyCBIJBJ8+kgwAj1scKO8GhErY3CjTNXi6/wadw1HL+fDVC7FkkeDsfqZMDx7jx8A4NuDf+LpyNOoqK5t0TVvLbnQ/2+tNgBbbojEwnBDRAbD3FSGHyP6w9POHFfzyzF91WmUqZofRPJKqvD+9rrHUfPv7wZ/ZyvIZVK89a+e+OqJPjAzkeLwpet4aV18i0Zm3epvE/bPcHOrzw1bbojalajh5siRI3jwwQfh4eEBiUSCrVu33vGcQ4cOoV+/flAoFOjSpQsiIyPbvE4i0h9utmZY/UwYHC1NcT6rGM//HNusEU+CIOCtrRdQUlWLXp622taaW8b38cTaZwdAIZdif3Ie3t6WCEG48yOq0qoanLtWDAAI86sfbnwcLQHUtdw051pEpBuihpvy8nIEBwfj22+/bdbxqampGDduHIYPH46EhATMmzcPzz77LPbs2dPGlRKRPunsbIXIGWGwUshx4s8bmLch4Y59ZXacz8Hei7mQSyX47yO9IZc1/PUX4uOAryf3hUQCrI/JwP8O/dnkNctVtXgmMhbVag062ZtrJ+67xdPOHFIJUFmjxvVWPEJrzLlrRVh3KoNhiagJooabsWPH4oMPPsDEiRObdfzy5cvh5+eHzz77DD169MCcOXPwyCOP4IsvvmjjSolI3/TqZIvvnwqBqUyK3YlKvLH5/G0DzvlrxXhj83kAwOzhXdDD3ea21x0d6Ib3HgoEACzZk4Lf4q41elyZqhbTV8UgJq0A1mZyLH2yHyQSSb1jTOVSuNuaA9DNoymNpq4z9RtbziP6zxt3fT0iY2VQfW6io6MxcuTIettGjx6N6Ojo256jUqlQUlJS70VExmFQFyd89UQfSCXAL7GZmLkmrkFn4AtZxZjyw0mUVNWiv689Zg/vcsfrTgv3xQtDOwMAXvvtHNadykBhebV2f5mqFtNXxuB0WiGszeRY88wA9PGya/Raupzr5uy1ImQXVwEAEq4V3fX1iIyVQYUbpVIJV1fXettcXV1RUlKCysrGF9ZbvHgxbG1ttS8vL6/2KJWI2snYXu74enJfmMqliLqYiye+P4m80roAUBdsTqGkqhYhPvZYNSMMpvLm/dp7bXQAHgr2QK1GwBtbziPkgyhM/N9xfLnvEiJWxiA2vRA2ZnKsfXYAgm8TbADodAHN3ReU2n8nZvMPNaLbMahw0xoLFixAcXGx9pWZmSl2SUSkY//q7YF1zw6AvYUJzl0rxsRvT2BbQham/HAKxZU16Odth8gZ/WGlkDf7mlKpBEse7Y25I7oiwM0aGgGIzyjCl/suIy69ELbmJlj33ED07mTX5HV0NRxcEATsTvwr3FxkuCG6reb/n64H3NzckJubW29bbm4ubGxsYG5u3ug5CoUCCoWiPcojIhGF+jpgy6zBmBF5Gqn55Zi7IQEA0NfbDj89HQZrM5MWX1Mhl+E/93fDf+7vhpziShy5dB2HL11HdlEVPpgQhCBP2zteQ1ePpZKVpUi/UQETmQQ1agGp+eUoU9W2KLARdRQG1XITHh6O/fv319sWFRWF8PBwkSoiIn3i62SJzS8O0s4308er9cHmn9xtzfF4f2/8b0oIts4e3KxgAwA+DnXDwe/2sdSum4+khnV3gbtt3SzISTlsvSFqjKiRv6ysDFeuXNG+T01NRUJCAhwcHODt7Y0FCxYgKysLP//8MwBg5syZWLp0KV599VU8/fTTOHDgADZu3IgdO3aI9SMQkZ6xtzTFmmcHIDatAP187GFmIhO1nlstN/llKlRU18LCtHW/dvfcDDdjAt0gCAJyiquQmFXcYFZkIhK55SY2NhZ9+/ZF3759AQDz589H37598c477wAAcnJykJHx1wrAfn5+2LFjB6KiohAcHIzPPvsMP/zwA0aPHi1K/USkn0zlUgzq4iR6sAEAWwsT2JrXtRy19tHU1etlSMkthVwqwcgerujpUddqdIH9bogaJWrLzbBhw5qciKqx2YeHDRuG+Pj4NqyKiEi3fBwtcO5aMdJvVCDArW6OnT2JSny+9xKeuccPj/VvehTnrY7E4f6OsLUwQaBH3TU4YoqocQbV54aIyBB53Xw0dWsl84MpeZiz7gxSckvx6m/nsPF006M4tY+kgtwAQBtuLueWQlV756UniDoahhsiojbm4/DXXDcnr97AzNVxqFEL2v44r20+h63xWY2em1VUibPXiiGRAKN61oUbTztz2JqboFYj4HJuWfv8EEQGhOGGiKiN3Qoxx6/k49mfYqGq1WBEgAv2zR+KqQO9IQjA/I0J2HEup8G5t1pt+vs4wNm6bloLiUTyt0dTxe30UxAZDoYbIqI2dmsiv6s356YJ7+yIb6f0g6lcikUPBeGx0E7QCMDcDfHYlpCF6lqN9txb/W1G33wkdcutoejsd0PUEGd/IiJqYz6Oltp/9/Gyw4qIUO1ILqlUgsUP90Z1rQZbE7Ixd0MCXpaeRRcXK3R3s8bptAIAf/W3uYWdioluj+GGiKiNuduY4b4AF1TVqPG/Kf0azCosk0rw6aPBsDE3wZb4LJRW1SJZWYpkZSkAoHcnW3ja1Z+F/Va4ScopgVojQCatvyI5UUfGcENE1MakUglWTu/f5DFymRSLxgfhvYcCkV1chaTsEiQrS5BRUIHJYd4NjvdzsoK5iQwV1Wqk5peji4tVW5VPZHAYboiI9IhEIoGnnTk87cwxsqfrbY+TSSUIcLdGfEYRErOLGW6I/oYdiomIDNStR1NcIZyoPoYbIiIDFejR+Iip+IxCfLonBZXVnOCPOiY+liIiMlB/n+tGEARIJBKcTivAtB9jUFmjhkIuxUsjuopcJVH7Y8sNEZGB6uZqDblUgsKKGuQUV+HctSLMWHUalTV1LTZrTqWjRq25w1WIjA/DDRGRgTIzkWk7Em8+cw3TVsagTFWLAX51sxnnlqiw6+YMx0QdCcMNEZEBu9Xv5tO9l1BUUYM+Xnb4cXp/TBlQN3w88niqmOURiYLhhojIgN3qdwMAPdxt8NOMMFgp5HhygDdMZBKcySjC2cwi8QokEgHDDRGRARvcxQkSCdDFxQqrnwmDrYUJAMDF2gz/6u0BAPjpRJqIFRK1P4YbIiID1t3NGodfGY7tL90DJytFvX3TB/kCAP44l4280ioRqiMSB8MNEZGB83a00C7E+XfBXnbo622HGrWA9acyRaiMSBwMN0RERuxW682aU+moruWwcOoYGG6IiIzY2CB3uFgrcL1UhV0XcsQuh6hdMNwQERkxU7kUUwf6AAAW/p6I1387h13nc1BcWSNyZURtRyIIgiB2Ee2ppKQEtra2KC4uho2NzZ1PICIycDfKVJjwv+PILKjUbpNJJQj0sIGZXIZajQZqAVBrNAjxtseCB3o02oeHSEwt+f5muCEi6gAqq9U4mXoDRy5dx+FL13H1evltjx3cxRHfPxUKSwWXHyT9wXDTBIYbIiIgs6AC57OKAdS14sgkEhRWVGPh74kor1ajn7cdVk3/a94cIrG15PubsZyIqAPycrCAl4NFg+1dXa0RsTIGZzKK8MSKk1j9TFiD+XOI9B07FBMRkVYfLzv88sJAOFkpkJRTgseWRyOzoELssohahOGGiIjqCXCzwaaZ4fC0M8fV/HKM+fIINsRkoIP1YiADxnBDREQN+DlZYtPMcPT3tUd5tRqvbz6PGZGnoSzmMg6k/xhuiIioUR525tjwfDjeGtcDpnIpDqVcx6gvDmN9TAbKVLVil0d0WxwtRUREd3QlrxTzN57FuWt1I6xM5VLc29UZD/Ryw4gerrA156gqalscCt4EhhsiotapVWvw47FUbDididT8v+bJMZFJcH9PV0wd6IPwzo6QSCQiVknGiuGmCQw3RER3RxAEpOSWYud5JXZfyMGl3DLtPn9nSzw10AcPh3SCjRlbc0h3GG6awHBDRKRbSTklWHsqHVvOZKG8Wg0AsDCV4bFQL8wY7AsfR0uRKyRjwHDTBIYbIqK2UVpVg63xWVh9Ml3bmiORAKN6uuK5IZ0R4mPPR1bUagw3TWC4ISJqW4Ig4PiVG/jh2FUcSrmu3e5pZ45+PvYI8bZDiI8DAtytYSLjoF1qHoabJjDcEBG1n8u5pfjxWCo2x2ehulZTb5+tuQnenxCEh4I9RKqODAnDTRMYboiI2l+5qhZnM4sQl16IuIxCnEkvRElV3Vw5z9zjh9fHBrAVh5rEcNMEhhsiIvHVqjX4LOoSlh36EwAQ5ueAb5/sB2drLtJJjWvJ9zdjMhERtTu5TIrXxgRg+dR+sFLIEZNagH99cxTRf94QuzQyAgw3REQkmjFB7tg6ezC6uFght0SFyStOYsoPJxH95w0u1EmtxsdSREQkujJVLT7ckYRNsZmo1dR9LfX3tcec+7ri3q5OHEJO7HPTFIYbIiL9da2wAssP/4mNp6+hWl03uqqbqxWeGuiDif06wUohF7lCEgvDTRMYboiI9F9uSRW+O3wVG05noOLmrMdWCjkm9fPEpJBO6OluAzlHV3UoDDdNYLghIjIcJVU1+C3uGlZHp+Pq3xbrNDeRoXcn25uTAtrjnq5OMDORiVgptTWGmyYw3BARGR6NRsDxP/Ox9mQGjv+Zj9Kbc+TcYm9hgsdCvfDkAG+uZWWkGG6awHBDRGTYNBoBf14vQ1x6Ic5kFOLo5XzkFFdp9w/t5oyH+3ki0MMWvo4WfHxlJBhumsBwQ0RkXNQaAQeS87DmZDoOX7peb59CLkVXVysEuNng/p6uGBHgwrBjoBhumsBwQ0RkvNJvlGNdTAZOXi3AJWUpKmvU9fa725phcpg3nujvBRcbM5GqpNZguGkCww0RUceg0QjIKKhAsrIEsWmF2ByfhYLyagCAXCrB6CA3/Pu+rujuZi1ypdQcDDdNYLghIuqYVLVq7DqvxJqT6YhNLwQASCTA+GAPzBvZDb5O7IiszxhumsBwQ0RESTklWHrgCnaczwEAyKQSPBbaCU+G+SDA3ZorlOshhpsmMNwQEdEtF7KK8eneFBxK+asjskIuRS9PW/TxskOorwOGBzhDIeccOmJjuGkCww0REf3T6bQCfHf4T8SkFqDkH3PoOFmZYnKYN54c4A13W3ORKiSGmyYw3BAR0e1oNAJSb5QjIaMI8ZmF2HcxD8qSujl0ZFIJRge64l+9PRDkYQsvB3Mu6NmOGG6awHBDRETNVaPWIOpiLn46kYZTqQX19lmbyRHoYYNenrYYHuCCMF8HzqHThhhumsBwQ0RErZGsLMGGmEzEpRciRVmqXbX8FkdLU4wKdMWYIHcM8ndkp2QdM7hw8+2332LJkiVQKpUIDg7GN998g7CwsEaPjYyMxIwZM+ptUygUqKqqavT4f2K4ISKiu1Wj1uBybhkSs4sRk1qAqKRcFFXUaPc7Wyvw1EAfTBngDUcrhYiVGo+WfH/L26mm2/rll18wf/58LF++HAMGDMCXX36J0aNHIyUlBS4uLo2eY2Njg5SUFO17PvMkIqL2ZCKToqeHDXp62ODRUC/UqDU4dbUAuy7kYE+iEtdLVfg86hKWHryCiX08MeMeXwS48Q/q9iJ6y82AAQPQv39/LF26FACg0Wjg5eWFl156Ca+//nqD4yMjIzFv3jwUFRW16vPYckNERG2pRq3BzvM5WHksFWevFWu3D/BzwJSBPhgd6Mqh5a1gMC031dXViIuLw4IFC7TbpFIpRo4ciejo6NueV1ZWBh8fH2g0GvTr1w8fffQRAgMDGz1WpVJBpVJp35eUlOjuByAiIvoHE5kU4/t44qFgD5zJKMTKY2nYdSEHp1ILcCq1AI6WpnisvxeeDPOGl4OF2OUaJVF7O+Xn50OtVsPV1bXedldXVyiVykbP6d69O1auXIlt27ZhzZo10Gg0GDRoEK5du9bo8YsXL4atra325eXlpfOfg4iI6J8kEglCfBzw7ZR+OP76fZg7oitcbRS4UV6NZYf+xNAlB/HS+ngkZhff+WLUIqI+lsrOzoanpydOnDiB8PBw7fZXX30Vhw8fxqlTp+54jZqaGvTo0QOTJ0/G+++/32B/Yy03Xl5efCxFRETtrlatwb6kPKw5mY5jV/K124d2c8aLw/wxwM+B/Uhvw2AeSzk5OUEmkyE3N7fe9tzcXLi5uTXrGiYmJujbty+uXLnS6H6FQgGFgj3ViYhIfHKZFGOC3DAmyA2J2cX47vBVbD+XjcOXruPwpesI9LDBlAE+eKiPB6wUoo/5MViiPpYyNTVFSEgI9u/fr92m0Wiwf//+ei05TVGr1Th//jzc3d3bqkwiIiKdC/SwxdeT++LQK8MxdaA3FHIpErNL8MaW8xjw4T68ueU8knLYT7Q1RB8t9csvvyAiIgLfffcdwsLC8OWXX2Ljxo1ITk6Gq6srpk2bBk9PTyxevBgAsGjRIgwcOBBdunRBUVERlixZgq1btyIuLg49e/a84+dxtBQREemjwvJq/HbmGtadysDV/HLt9iFdnfDiMH+Ed3bs0I+sDOaxFAA8/vjjuH79Ot555x0olUr06dMHu3fv1nYyzsjIgFT6VwNTYWEhnnvuOSiVStjb2yMkJAQnTpxoVrAhIiLSV/aWpnh2SGc8c48foq/ewNqTGdidqMTRy/k4ejkfwV52eHGoP0b1dIVU2nFDTnOI3nLT3thyQ0REhiKzoAIrjl7FL6czoaqtW+7Bz8kSMwb7YlK/TrDsQP1yDG75hfbEcENERIYmv0yFyONp+Dk6DSVVtQDqFu6cHOaNiEG+8LQzF7nCtsdw0wSGGyIiMlTlqlr8duYaVh1PQ+rNfjkyqQQP9HLH80M6o1cnW5ErbDsMN01guCEiIkOn0Qg4mJKHH4+l4sSfN7Tbwzs74vl7O2NoN2ej65fDcNMEhhsiIjImidnF+OFoKv44m41aTd1XelcXKzx3b2eM7+NhNOtYMdw0geGGiIiMUXZRJSJPpGHdqQyUqer65bhYKzBjsB+eHOANW3MTkSu8Oww3TWC4ISIiY1ZSVYP1pzKw8ngqckvqlh+yUsgxqZ8npg70QVdXa5ErbB2GmyYw3BARUUdQXavBtoQsrDh6FZdyy7TbB3Z2wFMDfTEq0BUmMlEXKmgRhpsmMNwQEVFHotEIOPHnDaw+mYaoi7m42S0HrjZ1j6wmhxnGIyuGmyYw3BARUUeVXVSJDTEZWBeTifyyukdWlqYyPN7fGzMG+8LLwULkCm+P4aYJDDdERNTRqWrV+D0hGz8cTUVKbikAQCoB7gtwxZMDvDC0mwtkejaUnOGmCQw3REREdQRBwJHL+fjh6FUcvZyv3e5ua4ZHQ73weH8vvZn9mOGmCQw3REREDV3JK8WGmEz8duYaCitqAAASCXBvV2dMDvPCiB7idkBmuGkCww0REdHtqWrV2JOYiw0xGfVmP3ayUuCRkE54NLQT/J2t2r0uhpsmMNwQERE1T1p+OX6JzcSm2GvaDsgAEOxlh0n9PPFgbw/YW5q2Sy0MN01guCEiImqZGrUG+5PysDE2E4cvXYf65nhyE5kEw7u7YEJfT9wX4AIzk7Zb6oHhpgkMN0RERK13vVSFP85mY3P8NVzIKtFut1bIMTrIDRP6eCLc31Hno60YbprAcENERKQbKcpSbE3Iwu8J2cgqqtRu93OyxP75Q3W6MnlLvr/lOvtUIiIi6lC6u1njtTEB+L9R3RGXUYit8VnYcT4Hfb3sdBpsWootN0RERKQz1bUalFbVwNFKodPrtuT723BWzCIiIiK9ZyqX6jzYtBTDDRERERkVhhsiIiIyKgw3REREZFQYboiIiMioMNwQERGRUWG4ISIiIqPCcENERERGheGGiIiIjArDDRERERkVhhsiIiIyKgw3REREZFQYboiIiMioMNwQERGRUZGLXUB7EwQBQN3S6URERGQYbn1v3/oeb0qHCzelpaUAAC8vL5ErISIiopYqLS2Fra1tk8dIhOZEICOi0WiQnZ0Na2trSCQSnV67pKQEXl5eyMzMhI2NjU6vTfXxXrcf3uv2w3vdfniv24+u7rUgCCgtLYWHhwek0qZ71XS4lhupVIpOnTq16WfY2Njwf5Z2wnvdfniv2w/vdfvhvW4/urjXd2qxuYUdiomIiMioMNwQERGRUWG40SGFQoF3330XCoVC7FKMHu91++G9bj+81+2H97r9iHGvO1yHYiIiIjJubLkhIiIio8JwQ0REREaF4YaIiIiMCsMNERERGRWGGx359ttv4evrCzMzMwwYMAAxMTFil2TwFi9ejP79+8Pa2houLi6YMGECUlJS6h1TVVWF2bNnw9HREVZWVpg0aRJyc3NFqth4fPzxx5BIJJg3b552G++17mRlZWHq1KlwdHSEubk5evXqhdjYWO1+QRDwzjvvwN3dHebm5hg5ciQuX74sYsWGSa1W4+2334afnx/Mzc3h7++P999/v97aRLzXrXfkyBE8+OCD8PDwgEQiwdatW+vtb869LSgowJQpU2BjYwM7Ozs888wzKCsru/viBLprGzZsEExNTYWVK1cKiYmJwnPPPSfY2dkJubm5Ypdm0EaPHi2sWrVKuHDhgpCQkCA88MADgre3t1BWVqY9ZubMmYKXl5ewf/9+ITY2Vhg4cKAwaNAgEas2fDExMYKvr6/Qu3dvYe7cudrtvNe6UVBQIPj4+AjTp08XTp06JVy9elXYs2ePcOXKFe0xH3/8sWBrayts3bpVOHv2rPDQQw8Jfn5+QmVlpYiVG54PP/xQcHR0FLZv3y6kpqYKmzZtEqysrISvvvpKewzvdevt3LlTePPNN4XNmzcLAIQtW7bU29+ceztmzBghODhYOHnypHD06FGhS5cuwuTJk++6NoYbHQgLCxNmz56tfa9WqwUPDw9h8eLFIlZlfPLy8gQAwuHDhwVBEISioiLBxMRE2LRpk/aYpKQkAYAQHR0tVpkGrbS0VOjatasQFRUlDB06VBtueK9157XXXhPuueee2+7XaDSCm5ubsGTJEu22oqIiQaFQCOvXr2+PEo3GuHHjhKeffrretocffliYMmWKIAi817r0z3DTnHt78eJFAYBw+vRp7TG7du0SJBKJkJWVdVf18LHUXaqurkZcXBxGjhyp3SaVSjFy5EhER0eLWJnxKS4uBgA4ODgAAOLi4lBTU1Pv3gcEBMDb25v3vpVmz56NcePG1bunAO+1Lv3+++8IDQ3Fo48+ChcXF/Tt2xcrVqzQ7k9NTYVSqax3r21tbTFgwADe6xYaNGgQ9u/fj0uXLgEAzp49i2PHjmHs2LEAeK/bUnPubXR0NOzs7BAaGqo9ZuTIkZBKpTh16tRdfX6HWzhT1/Lz86FWq+Hq6lpvu6urK5KTk0WqyvhoNBrMmzcPgwcPRlBQEABAqVTC1NQUdnZ29Y51dXWFUqkUoUrDtmHDBpw5cwanT59usI/3WneuXr2KZcuWYf78+XjjjTdw+vRp/Pvf/4apqSkiIiK097Ox3ym81y3z+uuvo6SkBAEBAZDJZFCr1fjwww8xZcoUAOC9bkPNubdKpRIuLi719svlcjg4ONz1/We4IYMwe/ZsXLhwAceOHRO7FKOUmZmJuXPnIioqCmZmZmKXY9Q0Gg1CQ0Px0UcfAQD69u2LCxcuYPny5YiIiBC5OuOyceNGrF27FuvWrUNgYCASEhIwb948eHh48F4bOT6WuktOTk6QyWQNRo3k5ubCzc1NpKqMy5w5c7B9+3YcPHgQnTp10m53c3NDdXU1ioqK6h3Pe99ycXFxyMvLQ79+/SCXyyGXy3H48GF8/fXXkMvlcHV15b3WEXd3d/Ts2bPeth49eiAjIwMAtPeTv1Pu3v/93//h9ddfxxNPPIFevXrhqaeewn/+8x8sXrwYAO91W2rOvXVzc0NeXl69/bW1tSgoKLjr+89wc5dMTU0REhKC/fv3a7dpNBrs378f4eHhIlZm+ARBwJw5c7BlyxYcOHAAfn5+9faHhITAxMSk3r1PSUlBRkYG730LjRgxAufPn0dCQoL2FRoaiilTpmj/zXutG4MHD24wpcGlS5fg4+MDAPDz84Obm1u9e11SUoJTp07xXrdQRUUFpNL6X3MymQwajQYA73Vbas69DQ8PR1FREeLi4rTHHDhwABqNBgMGDLi7Au6qOzIJglA3FFyhUAiRkZHCxYsXheeff16ws7MTlEql2KUZtBdffFGwtbUVDh06JOTk5GhfFRUV2mNmzpwpeHt7CwcOHBBiY2OF8PBwITw8XMSqjcffR0sJAu+1rsTExAhyuVz48MMPhcuXLwtr164VLCwshDVr1miP+fjjjwU7Ozth27Ztwrlz54Tx48dzeHIrRERECJ6entqh4Js3bxacnJyEV199VXsM73XrlZaWCvHx8UJ8fLwAQPj888+F+Ph4IT09XRCE5t3bMWPGCH379hVOnTolHDt2TOjatSuHguuTb775RvD29hZMTU2FsLAw4eTJk2KXZPAANPpatWqV9pjKykph1qxZgr29vWBhYSFMnDhRyMnJEa9oI/LPcMN7rTt//PGHEBQUJCgUCiEgIED4/vvv6+3XaDTC22+/Lbi6ugoKhUIYMWKEkJKSIlK1hqukpESYO3eu4O3tLZiZmQmdO3cW3nzzTUGlUmmP4b1uvYMHDzb6OzoiIkIQhObd2xs3bgiTJ08WrKysBBsbG2HGjBlCaWnpXdcmEYS/TdVIREREZODY54aIiIiMCsMNERERGRWGGyIiIjIqDDdERERkVBhuiIiIyKgw3BAREZFRYbghIiIio8JwQ0QdkkQiwdatW8Uug4jaAMMNEbW76dOnQyKRNHiNGTNG7NKIyAjIxS6AiDqmMWPGYNWqVfW2KRQKkaohImPClhsiEoVCoYCbm1u9l729PYC6R0bLli3D2LFjYW5ujs6dO+PXX3+td/758+dx3333wdzcHI6Ojnj++edRVlZW75iVK1ciMDAQCoUC7u7umDNnTr39+fn5mDhxIiwsLNC1a1f8/vvv2n2FhYWYMmUKnJ2dYW5ujq5duzYIY0SknxhuiEgvvf3225g0aRLOnj2LKVOm4IknnkBSUhIAoLy8HKNHj4a9vT1Onz6NTZs2Yd++ffXCy7JlyzB79mw8//zzOH/+PH7//Xd06dKl3me89957eOyxx3Du3Dk88MADmDJlCgoKCrSff/HiRezatQtJSUlYtmwZnJyc2u8GEFHr3fXSm0RELRQRESHIZDLB0tKy3uvDDz8UBKFuRfiZM2fWO2fAgAHCiy++KAiCIHz//feCvb29UFZWpt2/Y8cOQSqVCkqlUhAEQfDw8BDefPPN29YAQHjrrbe078vKygQAwq5duwRBEIQHH3xQmDFjhm5+YCJqV+xzQ0SiGD58OJYtW1Zvm4ODg/bf4eHh9faFh4cjISEBAJCUlITg4GBYWlpq9w8ePBgajQYpKSmQSCTIzs7GiBEjmqyhd+/e2n9bWlrCxsYGeXl5AIAXX3wRkyZNwpkzZzBq1ChMmDABgwYNatXPSkTti+GGiERhaWnZ4DGRrpibmzfrOBMTk3rvJRIJNBoNAGDs2LFIT0/Hzp07ERUVhREjRmD27Nn49NNPdV4vEekW+9wQkV46efJkg/c9evQAAPTo0QNnz55FeXm5dv/x48chlUrRvXt3WFtbw9fXF/v377+rGpydnREREYE1a9bgyy+/xPfff39X1yOi9sGWGyIShUqlglKprLdNLpdrO+1u2rQJoaGhuOeee7B27VrExMTgxx9/BABMmTIF7777LiIiIrBw4UJcv34dL730Ep566im4uroCABYuXIiZM2fCxcUFY8eORWlpKY4fP46XXnqpWfW98847CAkJQWBgIFQqFbZv364NV0Sk3xhuiEgUu3fvhru7e71t3bt3R3JyMoC6kUwbNmzArFmz4O7ujvXr16Nnz54AAAsLC+zZswdz585F//79YWFhgUmTJuHzzz/XXisiIgJVVVX44osv8Morr8DJyQmPPPJIs+szNTXFggULkJaWBnNzcwwZMgQbNmzQwU9ORG1NIgiCIHYRRER/J5FIsGXLFkyYMEHsUojIALHPDRERERkVhhsiIiIyKuxzQ0R6h0/LiehusOWGiIiIjArDDRERERkVhhsiIiIyKgw3REREZFQYboiIiMioMNwQERGRUWG4ISIiIqPCcENERERGheGGiIiIjMr/A5nyNX5nnkrgAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting training loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'])\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Awesome, now you have succesfully trained a transformers model.\n",
    "### Now let's try some practice excercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice excercise 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practice exercise, let's train the model using \"he_uniform\" initializer instead of \"glorot_uniform\". Then, compare the training loss between model using \"glorot_uniform\" vs \"he_uniform\" initializers by plotting them using matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.0800 - loss: 2.8303\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.2800 - loss: 2.7820\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.2400 - loss: 2.7269\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.2400 - loss: 2.6550\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.2400 - loss: 2.5572\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.2400 - loss: 2.4328\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.2400 - loss: 2.3209\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.2400 - loss: 2.3251\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.2800 - loss: 2.2894\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.3200 - loss: 2.2065\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.3200 - loss: 2.1561\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.2000 - loss: 2.1202\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.2000 - loss: 2.0749\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.3200 - loss: 2.0154\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.3200 - loss: 1.9448\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.3200 - loss: 1.8749\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.3200 - loss: 1.8227\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.3200 - loss: 1.7926\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.3200 - loss: 1.7635\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.3200 - loss: 1.7223\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.3200 - loss: 1.6803\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.3200 - loss: 1.6482\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.3600 - loss: 1.6200\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.2800 - loss: 1.5721\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.3200 - loss: 1.5181\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.3200 - loss: 1.5217\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.3200 - loss: 1.5419\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.3200 - loss: 1.5155\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.3200 - loss: 1.4842\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.3200 - loss: 1.4609\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.3200 - loss: 1.4592\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.3200 - loss: 1.4778\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.3200 - loss: 1.4615\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.3200 - loss: 1.4508\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.3200 - loss: 1.4369\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.3600 - loss: 1.4152\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.3200 - loss: 1.4242\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 0.3200 - loss: 1.4141\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.3600 - loss: 1.4047\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.3200 - loss: 1.3911\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.3200 - loss: 1.3765\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.3200 - loss: 1.3538\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.4000 - loss: 1.3416\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.4000 - loss: 1.3148\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.3600 - loss: 1.2902\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.4000 - loss: 1.2629\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.4400 - loss: 1.2259\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.5600 - loss: 1.1806\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.5600 - loss: 1.1370\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.5200 - loss: 1.0955\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.5200 - loss: 1.0692\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.6400 - loss: 1.0124\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.6400 - loss: 0.9746\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.6800 - loss: 0.9799\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.6400 - loss: 0.9324\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.7600 - loss: 0.8783\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.6800 - loss: 0.8687\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.6400 - loss: 0.9078\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.6000 - loss: 0.8804\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.6400 - loss: 0.8467\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.6400 - loss: 0.7819\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.6800 - loss: 0.7764\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.7200 - loss: 0.7534\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7600 - loss: 0.6890\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.6800 - loss: 0.7160\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.6800 - loss: 0.6965\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7600 - loss: 0.7161\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7200 - loss: 0.7057\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.6800 - loss: 0.6764\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.7200 - loss: 0.6413\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7200 - loss: 0.6310\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.8400 - loss: 0.6203\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7200 - loss: 0.6050\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7200 - loss: 0.5826\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7600 - loss: 0.5543\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.8400 - loss: 0.5354\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.8400 - loss: 0.5029\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.7600 - loss: 0.4987\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.8400 - loss: 0.5053\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.8800 - loss: 0.4713\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.7600 - loss: 0.4773\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.8400 - loss: 0.4319\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8800 - loss: 0.4301\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9600 - loss: 0.4028\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.8800 - loss: 0.3918\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9200 - loss: 0.3797\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.9200 - loss: 0.3767\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9600 - loss: 0.3628\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9200 - loss: 0.3512\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.9600 - loss: 0.3350\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 0.3190\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.9600 - loss: 0.3031\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.9600 - loss: 0.2884\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.9600 - loss: 0.2749\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 1.0000 - loss: 0.2614\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 1.0000 - loss: 0.2452\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 1.0000 - loss: 0.2298\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 1.0000 - loss: 0.2136\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step - accuracy: 1.0000 - loss: 0.1979\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 1.0000 - loss: 0.1822\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Write your answer here\n",
    "#Define the Self-Attention Layer\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    \n",
    "#Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "#Attention Mechanism\n",
    "attention_layer = SelfAttention()(encoder_outputs)\n",
    "\n",
    "#Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,))\n",
    "decoder_embedding = Embedding(output_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_attention = SelfAttention()(decoder_outputs)  # Apply attention\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_attention)\n",
    "\n",
    "#Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Step 6: Train the Model\n",
    "history_he = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"glorot_uniform\", color='red')\n",
    "plt.plot(history_he.history['loss'], label=\"he_uniform\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "\n",
    "\n",
    "#Define the Self-Attention Layer\n",
    "class SelfAttention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        feature_dim = input_shape[-1]\n",
    "        # Weight matrices for Q, K, V\n",
    "        self.Wq = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wq')\n",
    "        self.Wk = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wk')\n",
    "        self.Wv = self.add_weight(shape=(feature_dim, feature_dim), \n",
    "                                  initializer='he_uniform', \n",
    "                                  trainable=True, \n",
    "                                  name='Wv')\n",
    "        super(SelfAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Linear projections\n",
    "        q = K.dot(inputs, self.Wq)  # Query\n",
    "        k = K.dot(inputs, self.Wk)  # Key\n",
    "        v = K.dot(inputs, self.Wv)  # Value\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scores = K.batch_dot(q, k, axes=[2, 2])  # (batch, seq_len, seq_len)\n",
    "        scores = scores / K.sqrt(K.cast(K.shape(k)[-1], dtype=K.floatx()))  # Scale\n",
    "        attention_weights = K.softmax(scores, axis=-1)  # Normalize\n",
    "\n",
    "        # Weighted sum of values\n",
    "        output = K.batch_dot(attention_weights, v)  # (batch, seq_len, feature_dim)\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    \n",
    "#Encoder\n",
    "encoder_inputs = Input(shape=(max_input_length,))\n",
    "encoder_embedding = Embedding(input_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "#Attention Mechanism\n",
    "attention_layer = SelfAttention()(encoder_outputs)\n",
    "\n",
    "#Decoder\n",
    "decoder_inputs = Input(shape=(max_output_length - 1,))\n",
    "decoder_embedding = Embedding(output_vocab_size, 256)(decoder_inputs)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_attention = SelfAttention()(decoder_outputs)  # Apply attention\n",
    "decoder_dense = Dense(output_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_attention)\n",
    "\n",
    "#Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Step 6: Train the Model\n",
    "history_he = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"glorot_uniform\", color='red')\n",
    "plt.plot(history_he.history['loss'], label=\"he_uniform\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice excercise 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practice exercise, try to use adaptive gradient optimizer instead of adam. Then, plot and compare the results between adam and adaptive gradient optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write your answer here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "\n",
    "<!-- Your answer is below:\n",
    "\n",
    "#Full Model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#Step 6: Train the Model\n",
    "history_adagrad = model.fit([input_sequences, decoder_input_data], decoder_output_data, epochs=100, batch_size=16)\n",
    "\n",
    "#Plotting training losses for glorot_uniform and he_uniform inititalizers\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history_glorot_adam.history['loss'], label=\"adam\", color='red')\n",
    "plt.plot(history_adagrad.history['loss'], label=\"adagrad\", color='blue')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by [Aman Aggarwal](https://www.linkedin.com/in/aggarwal-aman/). I hope you found this lab interesting and educational. Feel free to contact me if you have any questions!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change Log\n",
    "\n",
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2024-11-20  | 1.0  | Aman  |  Created the lab |\n",
    "<hr>\n",
    "-->\n",
    "## <h3 align=\"center\"> © IBM Corporation. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "89fa9a3db18ab099ea8b241e966f29a2f658cfbd6a742128f10daea40c67df82"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
